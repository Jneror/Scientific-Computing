{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> ILI285 - Computación Científica I  / INF285 - Computación Científica </h1>\n",
    "    <h2> Linear Systems of Equations </h2>\n",
    "    <h2> [[S]cientific [C]omputing [T]eam](#acknowledgements)</h2>\n",
    "    <h2> Version: 1.1</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "* [Direct Methods](#DM)\n",
    "* [LU](#lu)\n",
    "* [Palu](#palu)\n",
    "* [Cholesky](#cholesky)\n",
    "* [Iterative Methods](#im)\n",
    "* [Convergence Analysis](#ca)\n",
    "* [Exercises](#ex)\n",
    "* [Acknowledgements](#acknowledgements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='intro' />\n",
    "## Introduction\n",
    "\n",
    "In our last IPython Notebook we learned how to solve 1D equations. Now, we'll go to the next level and will learn how to solve not just <i>one</i> equation, but a <i>system</i> of linear equations. This is a set of $n$ equations involving $n$ variables wherein all the equations must be satisfied at the same time. You probably know how to solve small 2D systems with methods such as substitution and reduction, but in practical real-life situations it's very likely that you'll find problems of bigger dimensions. As usual, we'll present some useful methods for solving systems of linear equations below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='DM' />\n",
    "## Direct Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we will study _direct methods_. They compute the analytic solution of the system (from here comes the name **direct**) limited only by the loss of numerical precision, because of the arithmetic operations performed by the computer. Their counterpart is the _iterative methods_, which calculate an approximate solution that evolves iteratively converging to the real solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='lu' />\n",
    "### LU decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the matrix $A \\in \\mathbb{R}^{n \\times n}$ square and non singular, the main goal of this method involves finding a decomposition like $A = L U$ where $L,U \\in  \\mathbb{R}^{n \\times n}$ are lower and upper triangular matrices respectively.\n",
    "\n",
    "The algorithm to perform this decomposition is basically a modified version of _Gaussian Elimination_. It basically iterates through the first $n-1$ columns, making $0$ all the entries below the main diagonal. This is accomplished by performing row operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lu_decomp(A, show=False):\n",
    "    N,_ = A.shape\n",
    "    U = np.copy(A)\n",
    "    L = np.identity(N)\n",
    "    if show:\n",
    "        print('Initial matrices')\n",
    "        print('L = '); print(np.array_str(L, precision=2, suppress_small=True))\n",
    "        print('U = '); print(np.array_str(U, precision=2, suppress_small=True))\n",
    "        print('----------------------------------------')\n",
    "    #iterating through columns\n",
    "    for j in range(N-1):\n",
    "        #iterating through rows\n",
    "        for i in range(j+1,N):\n",
    "            L[i,j] = U[i,j]/U[j,j]\n",
    "            U[i] -= L[i,j]*U[j] \n",
    "            if show:\n",
    "                print('L = '); print(np.array_str(L, precision=2, suppress_small=True))\n",
    "                print('U = '); print(np.array_str(U, precision=2, suppress_small=True))\n",
    "                print('----------------------------------------')\n",
    "    return L,U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the decomposition is done, solving a linear system like $A x = b$ is straightforward:\n",
    "\n",
    "$$A x = b \\rightarrow L U x = b \\ \\ \\text{ if we set } \\ \\  U x = c \\rightarrow L c = b \\ \\ \\text{ (solve for c) } \\ \\rightarrow U x = c$$\n",
    "\n",
    "and as you might know, solving lower and upper triangular systems can be easily performed by back-substitution and forward-subsitution respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solves a linear system A x = b, where A is a\n",
    "triangular (upper or lower) matrix\n",
    "\"\"\"\n",
    "def solve_triangular(A, b, upper=True):\n",
    "    n = b.shape[0]\n",
    "    x = np.zeros_like(b)\n",
    "    if upper==True:\n",
    "        #perform back-substitution\n",
    "        x[-1] = (1./A[-1,-1]) * b[-1]\n",
    "        for i in range(n-2, -1, -1):\n",
    "            x[i] = (1./A[i,i]) * (b[i] - np.sum(A[i,i+1:] * x[i+1:]))\n",
    "    else:\n",
    "        #perform forward-substitution\n",
    "        x[0] = (1./A[0,0]) * b[0]\n",
    "        for i in range(1,n):\n",
    "            x[i] = (1./A[i,i]) * (b[i] - np.sum(A[i,:i] * x[:i]))\n",
    "    return x\n",
    "\n",
    "def solve_lu(A, b, show=False):\n",
    "    L,U = lu_decomp(A, show)\n",
    "    # L.c = b with c = U.x\n",
    "    c = solve_triangular(L, b, upper=False)\n",
    "    x = solve_triangular(U, c)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try our implementations. We begin by creating a random 100$\\times$100 linear system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.random((3,3))\n",
    "b = np.ones(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we compute the solution with our LU solver, and aditionally with the NumPy solver which computes the solution using LAPACK routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial matrices\n",
      "L = \n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "U = \n",
      "[[0.9  0.78 0.82]\n",
      " [0.95 0.21 0.86]\n",
      " [0.49 0.94 0.11]]\n",
      "----------------------------------------\n",
      "L = \n",
      "[[1.   0.   0.  ]\n",
      " [1.05 1.   0.  ]\n",
      " [0.   0.   1.  ]]\n",
      "U = \n",
      "[[ 0.9   0.78  0.82]\n",
      " [ 0.   -0.61 -0.  ]\n",
      " [ 0.49  0.94  0.11]]\n",
      "----------------------------------------\n",
      "L = \n",
      "[[1.   0.   0.  ]\n",
      " [1.05 1.   0.  ]\n",
      " [0.54 0.   1.  ]]\n",
      "U = \n",
      "[[ 0.9   0.78  0.82]\n",
      " [ 0.   -0.61 -0.  ]\n",
      " [ 0.    0.52 -0.33]]\n",
      "----------------------------------------\n",
      "L = \n",
      "[[ 1.    0.    0.  ]\n",
      " [ 1.05  1.    0.  ]\n",
      " [ 0.54 -0.85  1.  ]]\n",
      "U = \n",
      "[[ 0.9   0.78  0.82]\n",
      " [ 0.   -0.61 -0.  ]\n",
      " [ 0.    0.   -0.33]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lu_sol = solve_lu(A,b, show=True)\n",
    "np_sol = np.linalg.solve(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to compare these huge vectors, we use the Euclidean metric as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.423651445728339e-16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(lu_sol - np_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is a very good result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method has two important facts to be noted:\n",
    "\n",
    "1. Computing the LU decomposition requires $2n^3/3$ floating point operations. Can you check that?\n",
    "2. When computing the LU decomposition you can see the instruction `L[i,j] = U[i,j]/U[j,j]`. Here we divide an entry below the main diagonal by the _pivot_ value. What happens if the pivot equals 0? How can we prevent that? **Answer:** PALU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='palu' />\n",
    "### PALU decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might've noted previously, LU has a problem when a _pivot_ has the value of $0$. To handle this problem, we add row permutations to the original LU algorithm. The procedure is as follows:\n",
    "\n",
    "1. When visiting the row $j$, search for $\\max(|a_{j,j}|,\\ |a_{j+1,j}|,\\ \\ldots,\\ |a_{N-1,j}|,\\ |a_{N,j}|)$ (the maximum between the pivot and the entries below it).\n",
    "2. If such maximum is $|a_{j,k}| \\neq |a_{j,j}|$, permutate rows $i$ and $k$ making $a_{j,k}$ the new pivot.\n",
    "\n",
    "To keep track of all the permutations performed, we use the permutation matrix $P$. It's inicially an identity matrix which permutes its rows in the same way the algorithm does on the resulting matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation between rows i and j on matrix A\n",
    "def row_perm(A, i, j):\n",
    "    tmp = np.copy(A[i])\n",
    "    A[i] = A[j]\n",
    "    A[j] = tmp\n",
    "\n",
    "def palu_decomp(A, show=False):\n",
    "    N,_ = A.shape\n",
    "    P = np.identity(N)\n",
    "    L = np.zeros((N,N))\n",
    "    U = np.copy(A)\n",
    "    if show:\n",
    "        print('Initial matrices')\n",
    "        print('P = '); print(np.array_str(P, precision=2, suppress_small=True))\n",
    "        print('L = '); print(np.array_str(L, precision=2, suppress_small=True))\n",
    "        print('U = '); print(np.array_str(U, precision=2, suppress_small=True))\n",
    "        print('----------------------------------------')\n",
    "    #iterating through columns\n",
    "    for j in range(N-1):\n",
    "        #determine the new pivot\n",
    "        p_index = np.argmax(np.abs(U[j:,j]))\n",
    "        if p_index != 0:\n",
    "            row_perm(P, j, j+p_index)\n",
    "            row_perm(U, j, j+p_index)\n",
    "            row_perm(L, j, j+p_index)\n",
    "            if show:\n",
    "                print('A permutation has been made')\n",
    "                print('P = '); print(np.array_str(P, precision=2, suppress_small=True))\n",
    "                print('L = '); print(np.array_str(L, precision=2, suppress_small=True))\n",
    "                print('U = '); print(np.array_str(U, precision=2, suppress_small=True))\n",
    "                print('----------------------------------------')\n",
    "        #iterating through rows\n",
    "        for i in range(j+1,N):\n",
    "            L[i,j] = U[i,j]/U[j,j]\n",
    "            U[i] -= L[i,j]*U[j]\n",
    "            if show:\n",
    "                print('P = '); print(np.array_str(P, precision=2, suppress_small=True))\n",
    "                print('L = '); print(np.array_str(L, precision=2, suppress_small=True))\n",
    "                print('U = '); print(np.array_str(U, precision=2, suppress_small=True))\n",
    "                print('----------------------------------------')\n",
    "    np.fill_diagonal(L,1)\n",
    "    return P,L,U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure to solve the system $Ax=b$ remains almost the same. We have to add the efect of the permutation matrix $P$:\n",
    "\n",
    "$$A x = b \\rightarrow P A x = P b \\rightarrow L U x = b' \\ \\ \\text{ if we set } \\ \\  U x = c \\rightarrow L c = b' \\ \\ \\text{ (solve for c) } \\ \\rightarrow U x = c$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_palu(A, b, show=False):\n",
    "    P,L,U = palu_decomp(A, show)\n",
    "    #A.x = b -> P.A.x = P.b = b'\n",
    "    b = np.dot(P,b)\n",
    "    # L.c = b' with c = U.x\n",
    "    c = solve_triangular(L, b, upper=False)\n",
    "    x = solve_triangular(U, c)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this new method against the LU and NumPy solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial matrices\n",
      "P = \n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "L = \n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "U = \n",
      "[[0.9  0.78 0.82]\n",
      " [0.95 0.21 0.86]\n",
      " [0.49 0.94 0.11]]\n",
      "----------------------------------------\n",
      "A permutation has been made\n",
      "P = \n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "L = \n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "U = \n",
      "[[0.95 0.21 0.86]\n",
      " [0.9  0.78 0.82]\n",
      " [0.49 0.94 0.11]]\n",
      "----------------------------------------\n",
      "P = \n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "L = \n",
      "[[0.   0.   0.  ]\n",
      " [0.95 0.   0.  ]\n",
      " [0.   0.   0.  ]]\n",
      "U = \n",
      "[[0.95 0.21 0.86]\n",
      " [0.   0.58 0.  ]\n",
      " [0.49 0.94 0.11]]\n",
      "----------------------------------------\n",
      "P = \n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "L = \n",
      "[[0.   0.   0.  ]\n",
      " [0.95 0.   0.  ]\n",
      " [0.51 0.   0.  ]]\n",
      "U = \n",
      "[[ 0.95  0.21  0.86]\n",
      " [ 0.    0.58  0.  ]\n",
      " [ 0.    0.83 -0.33]]\n",
      "----------------------------------------\n",
      "A permutation has been made\n",
      "P = \n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "L = \n",
      "[[0.   0.   0.  ]\n",
      " [0.51 0.   0.  ]\n",
      " [0.95 0.   0.  ]]\n",
      "U = \n",
      "[[ 0.95  0.21  0.86]\n",
      " [ 0.    0.83 -0.33]\n",
      " [ 0.    0.58  0.  ]]\n",
      "----------------------------------------\n",
      "P = \n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "L = \n",
      "[[0.   0.   0.  ]\n",
      " [0.51 0.   0.  ]\n",
      " [0.95 0.7  0.  ]]\n",
      "U = \n",
      "[[ 0.95  0.21  0.86]\n",
      " [ 0.    0.83 -0.33]\n",
      " [ 0.    0.    0.23]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "palu_sol = solve_palu(A, b, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.742874840267547e-16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(palu_sol - lu_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3263411494723067e-16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(palu_sol - np_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some questions about PALU:\n",
    "1. How much computational complexity has been added to the original $2n^3/3$ of LU?\n",
    "2. Clearly PALU is more robust than LU, but given a non sigular matrix $A$ will it always be possible to perform the PALU decomposition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='cholesky' />\n",
    "### Cholesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another direct method only applicable to _symmetric positive-definite_ matrices. In order to try this algorithm we have to create this kind of matrices. The next function generates random _symmetric positive-definite_ matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Randomly generates an nxn symmetric positive-\n",
    "definite matrix A.\n",
    "\"\"\"\n",
    "def generate_spd_matrix(n):\n",
    "    A = np.random.random((n,n))\n",
    "    #constructing symmetry\n",
    "    A += A.T\n",
    "    #symmetric+diagonally dominant -> symmetric positive-definite\n",
    "    deltas = 0.1*np.random.random(n)\n",
    "    row_sum = A.sum(axis=1)-np.diag(A)\n",
    "    np.fill_diagonal(A, row_sum+deltas)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a symmetric positive-definite matrix $A \\in \\mathbb{R}^{n \\times n}$, the Cholesky decomposition is of the form $A =R^T R$, with $R$ being an upper triangular matrix. This method takes advantage of the properties of symmetric matrices, reaching approximately twice the efficiency of LU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky_decomp(A, show=False):\n",
    "    N,_ = A.shape\n",
    "    A = np.copy(A)\n",
    "    R = np.zeros((N,N))\n",
    "    if show:\n",
    "        print('Initial matrix')\n",
    "        print('A = '); print(np.array_str(A, precision=2, suppress_small=True))\n",
    "        print('R = '); print(np.array_str(R, precision=2, suppress_small=True))\n",
    "        print('----------------------------------------')\n",
    "    for i in range(N):\n",
    "        R[i,i] = np.sqrt(A[i,i])\n",
    "        u = (1./R[i,i])*A[i,i+1:]\n",
    "        R[i,i+1:] = u\n",
    "        A[i+1:,i+1:] -= np.outer(u,u)\n",
    "        if show:\n",
    "            print('A = '); print(np.array_str(A, precision=2, suppress_small=True))\n",
    "            print('R = '); print(np.array_str(R, precision=2, suppress_small=True))\n",
    "            print('----------------------------------------')\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solve stage remains the same as LU:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_cholesky(A, b, show=False):\n",
    "    R = cholesky_decomp(A, show)\n",
    "    #R^T.R.x = b -> R^T.c = b with R.x = c\n",
    "    c = solve_triangular(R.T, b, upper=False)\n",
    "    x = solve_triangular(R, c)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test our implementation, comparing time execution with LU and PALU on two different linear systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = generate_spd_matrix(3)\n",
    "b = np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial matrix\n",
      "A = \n",
      "[[1.62 0.82 0.73]\n",
      " [0.82 2.04 1.16]\n",
      " [0.73 1.16 1.9 ]]\n",
      "R = \n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "----------------------------------------\n",
      "A = \n",
      "[[1.62 0.82 0.73]\n",
      " [0.82 1.63 0.79]\n",
      " [0.73 0.79 1.58]]\n",
      "R = \n",
      "[[1.27 0.64 0.57]\n",
      " [0.   0.   0.  ]\n",
      " [0.   0.   0.  ]]\n",
      "----------------------------------------\n",
      "A = \n",
      "[[1.62 0.82 0.73]\n",
      " [0.82 1.63 0.79]\n",
      " [0.73 0.79 1.19]]\n",
      "R = \n",
      "[[1.27 0.64 0.57]\n",
      " [0.   1.28 0.62]\n",
      " [0.   0.   0.  ]]\n",
      "----------------------------------------\n",
      "A = \n",
      "[[1.62 0.82 0.73]\n",
      " [0.82 1.63 0.79]\n",
      " [0.73 0.79 1.19]]\n",
      "R = \n",
      "[[1.27 0.64 0.57]\n",
      " [0.   1.28 0.62]\n",
      " [0.   0.   1.09]]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.409125  , 0.17761748, 0.26176751])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_cholesky(A, b, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = generate_spd_matrix(100)\n",
    "b = np.ones(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.16 ms ± 255 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "15.4 ms ± 1.13 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "The slowest run took 4.19 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "25.1 ms ± 16.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit solve_cholesky(A, b)\n",
    "%timeit solve_lu(A, b)\n",
    "%timeit solve_palu(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = generate_spd_matrix(1000)\n",
    "b = np.ones(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.09 s ± 58.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.09 s ± 42.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit solve_cholesky(A, b)\n",
    "%timeit solve_lu(A, b)\n",
    "%timeit solve_palu(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='im' />\n",
    "## Iterative Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Randomly generates an nxn strictly diagonally \n",
    "dominant matrix A.\n",
    "\"\"\"\n",
    "def generate_dd_matrix(n):\n",
    "    A = np.random.random((n,n))\n",
    "    deltas = 0.1*np.random.random(n)\n",
    "    row_sum = A.sum(axis=1)-np.diag(A)\n",
    "    np.fill_diagonal(A, row_sum+deltas)\n",
    "    return A\n",
    "\n",
    "\"\"\"\n",
    "Computes relative error between each row on \n",
    "X matrix and y vector. \n",
    "\"\"\"\n",
    "def error(X, y):\n",
    "    D = X-y\n",
    "    err = np.linalg.norm(D, axis=1, ord=np.inf)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we will create a linear system $A x = b$, with $A$ as a diagonally dominant matrix, which is a **sufficient** condition for the methods we will study in this section converge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3, -1, 0, 0, 0, 0.5],[-1, 3, -1, 0, 0.5, 0],[0, -1, 3, -1, 0, 0],[0, 0, -1, 3, -1, 0],\n",
    "              [0, 0.5, 0, -1, 3, -1],[0.5, 0, 0, 0, -1, 3]])\n",
    "b = np.array([2.5, 1.5, 1., 1., 1.5, 2.5])\n",
    "print ('A='); print (A)\n",
    "print ('b='); print (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and find the solution $x$ through `np.linalg.solve` to use it as the reference solution-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_sol = np.linalg.solve(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Jacobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterative methods implementations returns an array X\n",
    "with the the solutions at each iteration\n",
    "\"\"\"\n",
    "def jacobi(A, b, n_iter=50):\n",
    "    n = A.shape[0]\n",
    "    #array with solutions\n",
    "    X = np.empty((n_iter, n))\n",
    "    #initial guess\n",
    "    X[0] = np.zeros(n)\n",
    "    #submatrices\n",
    "    D = np.diag(A)\n",
    "    Dinv = D**-1\n",
    "    R = A - np.diag(D) #R=(L+U)\n",
    "    for i in range(1, n_iter):\n",
    "        X[i] = Dinv*(b - np.dot(R, X[i-1]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's resolve the same linear system with Jacobi method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_sol = jacobi(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_err = error(jac_sol, np_sol)\n",
    "it = np.linspace(1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.semilogy(it, jac_err, marker='o', linestyle='--', color='b')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Infinity norm error for Jacobi method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gauss Seidel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel(A, b, n_iter=50):\n",
    "    n = A.shape[0]\n",
    "    #array with solutions\n",
    "    X = np.empty((n_iter, n))\n",
    "    #initial guess\n",
    "    X[0] = np.zeros(n)\n",
    "    #submatrices\n",
    "    R = np.tril(A) #R=(L+D)\n",
    "    U = A-R\n",
    "    for i in range(1, n_iter):\n",
    "        X[i] = solve_triangular(R, b-np.dot(U, X[i-1]), upper=False)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's resolve the same linear system with Gauss-Seidel method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sol = gauss_seidel(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_err = error(gauss_sol, np_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.semilogy(it, gauss_err, marker='o', linestyle='--', color='r')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Infinity norm error for Gauss method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some questions about Gauss-Seidel:\n",
    "- Can you explain what the differences between this and Jacobi method are?\n",
    "- Why do we use `solve_triangular` instead of `np.linalg.solve` or something similar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sor(A, b, w=1.05, n_iter=50):\n",
    "    n = A.shape[0]\n",
    "    #array with solutions\n",
    "    X = np.empty((n_iter, n))\n",
    "    #initial guess\n",
    "    X[0] = np.zeros(n)\n",
    "    #submatrices\n",
    "    R = np.tril(A) #R=(L+D)\n",
    "    U = A-R\n",
    "    for i in range(1, n_iter):\n",
    "        X_i = solve_triangular(R, b-np.dot(U, X[i-1]), upper=False)\n",
    "        X[i] = w*X_i + (1-w)*X[i-1]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's resolve the same linear system with Jacobi method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sor_sol = sor(A, b, w=1.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sor_err = error(sor_sol, np_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.semilogy(it, sor_err, marker='o', linestyle='--', color='g')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Infinity norm error for SOR method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we choose a good value of $\\omega$? Well there are  some methods you could search, but for now we will try a naive way, i.e, computing the solution for a range $\\omega \\in [1,1.3]$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30 #width of subdivisions\n",
    "sor_solutions = list()\n",
    "for w in np.linspace(1., 1.3, n):\n",
    "    sor_solutions.append(sor(A, b, w, n_iter=5)[-1])\n",
    "np.asarray(sor_solutions)\n",
    "\n",
    "#now compute error solutions with each w\n",
    "sor_errors = error(sor_solutions, np_sol)\n",
    "w = np.linspace(1., 1.3, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see, we compute the SOR solution with 5 iterations for each $\\omega$ on the given range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.semilogy(w, sor_errors, marker='o', linestyle='--', color='g')\n",
    "plt.grid(True)\n",
    "plt.xlabel('w')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Infinity norm error after 5 steps of SOR as a function of w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some questions about SOR:\n",
    "- Why can averaging the current solution with the Gauss-Seidel solution improve convergence?\n",
    "- Why do we use $\\omega > 1$ and not $\\omega < 1$?\n",
    "- Could you describe a method to find the best value of $\\omega$ (the one which optimizes convergence)?\n",
    "- Would it be a better option to re-compute $\\omega$ at each iteration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='ca' />\n",
    "## Convergence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see convergence plots all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.semilogy(it, jac_err, marker='o', linestyle='--', color='b', label='Jacobi')\n",
    "plt.semilogy(it, gauss_err, marker='o', linestyle='--', color='r', label='Gauss-Seidel')\n",
    "plt.semilogy(it, sor_err, marker='o', linestyle='--', color='g', label='SOR')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Infinity norm error for all methods')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='ex' />\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how to solve systems of linear equations problem with these methods, let's try to answer a few questions!\n",
    "\n",
    "$a)$ Find the values of $\\alpha$ that make possible to do a LU descomposition of the following matrix:\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "   \\alpha & 2  \\\\[0.3em]\n",
    "   1 & \\alpha  \\end{bmatrix} $$\n",
    "\n",
    "$b)$- Let $A$ be the following matrix:\n",
    "\n",
    "$$ A = \\begin{bmatrix}\n",
    "        2 &  4 &  2  \\\\[0.3em]\n",
    "       -1 &  1 &  2  \\\\[0.3em]\n",
    "       -1 & -3 & -1  \\end{bmatrix} $$ \n",
    "       \n",
    "   - Find the PALU descomposition of the matrix $A$.\n",
    "   \n",
    "   - Solve the system of equations $Ax = \\[1 , \\frac{1}{2}, \\frac{1}{3}\\]^T$.\n",
    "\n",
    "$c)$ Considering this matrix:\n",
    "\n",
    "$$  \\begin{bmatrix}\n",
    "    1 & 1 & 0  \\\\[0.3em]\n",
    "    1 & 5 & 2  \\\\[0.3em]\n",
    "    0 & 2 & 3  \\end{bmatrix} $$\n",
    "       \n",
    "   - Find the LU descomposition.\n",
    "    \n",
    "   - Find the Cholesky descomposition.\n",
    "    \n",
    "   - Compare the efficiency of both methods.\n",
    "\n",
    "$d)$ Use Jacobi, Gauss Seidel, and SOR to solve the following system of equations (number of iterations = 2):\n",
    "\n",
    "$$2x + y = 3$$\n",
    "$$x + 2y = 2$$\n",
    "\n",
    "   - Which is the best method to solve this problem (with better results)?\n",
    "\n",
    "$e)$ Explain the pros and cons of using iterative methods instead of the direct ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Hilbert Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=20\n",
    "errors=np.zeros(N+1)\n",
    "kappas=np.zeros(N+1)\n",
    "my_range=np.arange(5,N+1)\n",
    "for n in my_range:\n",
    "    A=hilbert(n)\n",
    "    x_exact=np.ones(n)\n",
    "    b=np.dot(A,x_exact)\n",
    "    x=np.linalg.solve(A,b)\n",
    "    errors[n]=np.linalg.norm(x-x_exact,ord=np.inf)\n",
    "    kappas[n]=np.linalg.cond(A,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.semilogy(my_range, 10.**(-16+np.log10(kappas[my_range])), marker='o', linestyle='--', color='b',label='Estimated forward error')\n",
    "plt.semilogy(my_range, errors[my_range], marker='o', linestyle='--', color='r',label='Forward error')\n",
    "plt.grid(True)\n",
    "plt.xlabel('n')\n",
    "#plt.ylabel('$\\kappa$ and errors')\n",
    "plt.title('')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20\n",
    "A=hilbert(n)\n",
    "x_exact=np.ones(n)\n",
    "b=np.dot(A,x_exact)\n",
    "x=np.linalg.solve(A,b)\n",
    "kappa=np.linalg.cond(A,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(b-np.dot(A,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(x-x_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_exact[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='acknowledgements' />\n",
    "# Acknowledgements\n",
    "* _Material created by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) _and assistants: Laura Bermeo, Alvaro Salinas, Axel Simonsen and Martín Villanueva. DI UTFSM. April 2016._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
